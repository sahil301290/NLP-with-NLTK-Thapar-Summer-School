{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitinAShelke/NLP-with-NLTK-Thapar-Summer-School/blob/main/Day_3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_aJe0eWZob9"
      },
      "source": [
        "# Feature Extraction and Word Embeddings\n",
        "\n",
        "#### by Nitin Shelke"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1M_0ASQZocB"
      },
      "source": [
        "# Bag-of-words vectorization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ekUW547ZocE"
      },
      "outputs": [],
      "source": [
        "# Example 1\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['Text processing is necessary.', 'Text processing is necessary and important.', 'Text processing is easy.']\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLZn9gpsZocF"
      },
      "outputs": [],
      "source": [
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX0xEDs-ZocG"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "text = [\"i love NLP\",\n",
        "        \"NLP is future\",\n",
        "        \"i will learn in 2 months\"]\n",
        "vectorizer = CountVectorizer()\n",
        "count_matrix = vectorizer.fit_transform(text)\n",
        "count_array = count_matrix.toarray()\n",
        "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1ZcOiUBZocG"
      },
      "source": [
        "# TFIDF Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sUfeUIWZocI"
      },
      "outputs": [],
      "source": [
        "# TFIDF Vectorization code\n",
        "\n",
        "#Example 1\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())\n",
        "\n",
        "# The above array represents the vectors created for our 3 documents using the TFIDF vectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On5rh_9QZocI"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "import pandas as pd\n",
        "text = [\"i love the NLP\",\n",
        "        \"NLP is the future\",\n",
        "        \"i will learn the NLP\"]\n",
        "vectorizer = TfidfVectorizer()\n",
        "matrix = vectorizer.fit_transform(text)\n",
        "count_array = matrix.toarray()\n",
        "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzuoAadBZocJ"
      },
      "source": [
        "“NLP”, ”the” came in all the three documents hence it has a smaller vector value. ”love” has a higher vector value since it appeared only once in a document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8OvIo9tZocJ"
      },
      "source": [
        "# Word Embedding "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFHTmrqzZocJ"
      },
      "source": [
        "# Implementing Glove word embedding using python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zN5htp0ZocK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Loading glove word embedding of 100 dimensions into a dictionary:\n",
        "\n",
        "import numpy as np\n",
        "glove_vectors = dict()\n",
        "file = open('glove.6B.100d.txt', encoding = 'utf-8')\n",
        "for line in file:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vectors = np.asarray(values[1:])\n",
        "    glove_vectors[word] = vectors\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEUN5T2NZocK"
      },
      "outputs": [],
      "source": [
        "#we can use the get() method to glove_vectors to get the vectors\n",
        "glove_vectors.get('house')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJs5H5qqZocK"
      },
      "outputs": [],
      "source": [
        "# Creating a function that takes every sentence and returns word vectors:\n",
        "vec_dimension = 100\n",
        "def get_vec(x):\n",
        "    arr  = np.zeros(vec_dimension)\n",
        "    text = str(x).split()\n",
        "    for t in text:\n",
        "        try:\n",
        "            vec = glove_vectors.get(t).astype(float)\n",
        "            arr = arr + vec\n",
        "        except:\n",
        "            pass\n",
        "    arr = arr.reshape(1,-1)[0]\n",
        "    return(arr/len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4mtVyPhZocL"
      },
      "outputs": [],
      "source": [
        "x = ['I love you',\n",
        "     'I love NLP and i will try to learn',\n",
        "    'this is word embedding']\n",
        "features = get_vec(x)\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhWbMFTaZocL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt"
      ],
      "metadata": {
        "id": "m4Qa38idd2yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gEWIvmcid3Wz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day 3_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}